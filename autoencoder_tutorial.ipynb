{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "autoencoder_tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOFZGH_XZ2wK"
      },
      "source": [
        "# **Auto-Encoder Tutorial**\r\n",
        "##### *Tutorial for: Pitt RAS - Perception Sub-Team, Indy Autonomous Challenge*\r\n",
        "##### *December 2020*\r\n",
        "#####  *Morgan Visnesky*    \r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-RsLoyJagce"
      },
      "source": [
        "* In this tutorial we will be using Pytorch, Torchvision, and the MNIST dataset.\r\n",
        "* We will be building off of Noah Gasparro's sub-team presentation and use of Pytorch and MNIST."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glBBqMusc9mR"
      },
      "source": [
        "# **Purpose**\r\n",
        "* Demonstrate the use of auto-encoders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A655J4kpSZUY"
      },
      "source": [
        "# Install Requirements"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SByhnmTzfAUS"
      },
      "source": [
        "To start we need to install Pytorch and Torchvision.\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPx2L3yMZuSM"
      },
      "source": [
        "!pip3 install torch==1.7.0\r\n",
        "!pip3 install torchvision==0.7.0\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPK-Hc_jlO-t"
      },
      "source": [
        "# Import Pytorch and other required libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMNSvfXRkW7y"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "import torchvision\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxG0ynUskBIt"
      },
      "source": [
        "# Now we need to grab the data sets we will be using for this tutorial.\r\n",
        "As mentioned above, we will be using the MNIST dataset.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTOuS_pEZ2HU"
      },
      "source": [
        "#MNIST dataset\r\n",
        "\r\n",
        "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\r\n",
        "\r\n",
        "train_dataset = torchvision.datasets.MNIST(\r\n",
        "    root=\"~/torch_datasets\", train=True, transform=transform, download=True\r\n",
        ")\r\n",
        "\r\n",
        "test_dataset = torchvision.datasets.MNIST(\r\n",
        "    root=\"~/torch_datasets\", train=False, transform=transform, download=True\r\n",
        ")\r\n",
        "\r\n",
        "train_loader = torch.utils.data.DataLoader(\r\n",
        "    train_dataset, batch_size=128, shuffle=True, num_workers=4, pin_memory=True\r\n",
        ")\r\n",
        "\r\n",
        "test_loader = torch.utils.data.DataLoader(\r\n",
        "    test_dataset, batch_size=32, shuffle=False, num_workers=4\r\n",
        ")\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jY25ecNlmqP"
      },
      "source": [
        "# Lets take a look at some of our data!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9e7Kd_vj3gV"
      },
      "source": [
        "# functions to show an image\r\n",
        "\r\n",
        "def imshow(img):\r\n",
        "    npimg = img.numpy()\r\n",
        "    ax = plt.subplot(1,1,1)\r\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\r\n",
        "    ax.get_xaxis().set_visible(False)\r\n",
        "    ax.get_yaxis().set_visible(False)\r\n",
        "    plt.show()\r\n",
        "\r\n",
        "\r\n",
        "print(\"Examples of our dataset:\")\r\n",
        "for i in range(5):\r\n",
        "  # get some random training images\r\n",
        "  dataiter = iter(train_loader)\r\n",
        "  images, labels = dataiter.next()\r\n",
        "\r\n",
        "  # show images\r\n",
        "  imshow(torchvision.utils.make_grid(images[:8]))\r\n",
        "  # print labels\r\n",
        "  print(''.join('%5s' % str(labels[j]).strip('tensor(').rstrip(')') for j in range(8)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRQ2SRq8Zz1y"
      },
      "source": [
        "# Defining our Auto-Encoder (Example #1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I1tutBAEddCJ"
      },
      "source": [
        "\r\n",
        "class AE(nn.Module):\r\n",
        "    def __init__(self, **kwargs):\r\n",
        "        super().__init__()\r\n",
        "        self.encoder_hidden_layer = nn.Linear(\r\n",
        "            in_features=kwargs[\"input_shape\"], out_features=128\r\n",
        "        )\r\n",
        "        self.encoder_output_layer = nn.Linear(\r\n",
        "            in_features=128, out_features=128\r\n",
        "        )\r\n",
        "        self.decoder_hidden_layer = nn.Linear(\r\n",
        "            in_features=128, out_features=128\r\n",
        "        )\r\n",
        "        self.decoder_output_layer = nn.Linear(\r\n",
        "            in_features=128, out_features=kwargs[\"input_shape\"]\r\n",
        "        )\r\n",
        "\r\n",
        "    def forward(self, features):\r\n",
        "        activation = self.encoder_hidden_layer(features)\r\n",
        "        activation = torch.relu(activation)\r\n",
        "        code = self.encoder_output_layer(activation)\r\n",
        "        code = torch.relu(code)\r\n",
        "        activation = self.decoder_hidden_layer(code)\r\n",
        "        activation = torch.relu(activation)\r\n",
        "        activation = self.decoder_output_layer(activation)\r\n",
        "        reconstructed = torch.relu(activation)\r\n",
        "        return reconstructed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tzu9EYg8FN0B"
      },
      "source": [
        "# Defining our Auto-Encoder (Example #2)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDeIt0e09IaK"
      },
      "source": [
        "class AE(nn.Module):\r\n",
        "    def __init__(self, **kwargs):\r\n",
        "        super(AE, self).__init__()\r\n",
        "        # encoders\r\n",
        "        self.encoder_1 = nn.Linear(in_features=kwargs[\"input_shape\"], out_features=256) # downsamples from (28 X 28) to (16 X 16)\r\n",
        "        self.encoder_2 = nn.Linear(in_features=256, out_features=128) # downsamples\r\n",
        "        self.encoder_3 = nn.Linear(in_features=128, out_features=64) # downsamples\r\n",
        "        self.encoder_4 = nn.Linear(in_features=64, out_features=32) # downsamples\r\n",
        "        self.encoder_5 = nn.Linear(in_features=32, out_features=16) # downsamples to 4 x 4, or 16 total pixels\r\n",
        "        self.encoder_6 = nn.Linear(in_features=16, out_features=4)\r\n",
        "        # decoders \r\n",
        "        self.decoder_1 = nn.Linear(in_features=4, out_features=16) # upsamples\r\n",
        "        self.decoder_2 = nn.Linear(in_features=16, out_features=32) # upsamples\r\n",
        "        self.decoder_3 = nn.Linear(in_features=32, out_features=64) # upsamples\r\n",
        "        self.decoder_4 = nn.Linear(in_features=64, out_features=128) # upsamples\r\n",
        "        self.decoder_5 = nn.Linear(in_features=128, out_features=256) # upsamples\r\n",
        "        self.decoder_6 = nn.Linear(in_features=256, out_features=kwargs[\"input_shape\"]) # Final upsample to original size\r\n",
        "    \r\n",
        "    def forward(self, features):\r\n",
        "        x = torch.relu(self.encoder_1(features))\r\n",
        "        x = torch.relu(self.encoder_2(x))\r\n",
        "        x = torch.relu(self.encoder_3(x))\r\n",
        "        x = torch.relu(self.encoder_4(x))\r\n",
        "        x = torch.relu(self.encoder_5(x))\r\n",
        "        x = torch.relu(self.encoder_6(x))\r\n",
        "        x = torch.relu(self.decoder_1(x))\r\n",
        "        x = torch.relu(self.decoder_2(x))\r\n",
        "        x = torch.relu(self.decoder_3(x))\r\n",
        "        x = torch.relu(self.decoder_4(x))\r\n",
        "        x = torch.relu(self.decoder_5(x))\r\n",
        "        reconstruction = torch.relu(self.decoder_6(x))\r\n",
        "        return reconstruction"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H9Pa8FwZdes3"
      },
      "source": [
        "#  select GPU if one if available, otherwise CPU\r\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "\r\n",
        "# create a model from `AE` autoencoder class\r\n",
        "model = AE(input_shape=784).to(device)\r\n",
        "\r\n",
        "# visualize the encoder / docoder structure\r\n",
        "print(model)\r\n",
        "\r\n",
        "# create an optimizer object\r\n",
        "# Adam optimizer with learning rate 1e-3\r\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\r\n",
        "\r\n",
        "# mean-squared error loss\r\n",
        "criterion = nn.MSELoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m7ivSe0nDCjm"
      },
      "source": [
        "# Try changing the # of epochs below and visualizing the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYQARG-odk8W"
      },
      "source": [
        "epochs = 5\r\n",
        "for epoch in range(epochs):\r\n",
        "    loss = 0\r\n",
        "    for batch_features, _ in train_loader:\r\n",
        "        # reshape mini-batch data to [N, 784] matrix\r\n",
        "        # load it to the active device\r\n",
        "        batch_features = batch_features.view(-1, 784).to(device)\r\n",
        "        \r\n",
        "        # reset the gradients back to zero\r\n",
        "        # PyTorch accumulates gradients on subsequent backward passes\r\n",
        "        optimizer.zero_grad()\r\n",
        "        \r\n",
        "        # compute reconstructions\r\n",
        "        outputs = model(batch_features)\r\n",
        "        \r\n",
        "        # compute training reconstruction loss\r\n",
        "        train_loss = criterion(outputs, batch_features)\r\n",
        "        \r\n",
        "        # compute accumulated gradients\r\n",
        "        train_loss.backward()\r\n",
        "        \r\n",
        "        # perform parameter update based on current gradients\r\n",
        "        optimizer.step()\r\n",
        "        \r\n",
        "        # add the mini-batch training loss to epoch loss\r\n",
        "        loss += train_loss.item()\r\n",
        "    \r\n",
        "    # compute the epoch training loss\r\n",
        "    loss = loss / len(train_loader)\r\n",
        "    \r\n",
        "    # display the epoch training loss\r\n",
        "    print(\"epoch : {}/{}, loss = {:.6f}\".format(epoch + 1, epochs, loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u54gsCkwSIM6"
      },
      "source": [
        "# Visualize the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xW9i7F3OfmXB"
      },
      "source": [
        "test_loader = torch.utils.data.DataLoader(\r\n",
        "    test_dataset, batch_size=10, shuffle=True\r\n",
        ")\r\n",
        "\r\n",
        "test_examples = None\r\n",
        "\r\n",
        "with torch.no_grad():\r\n",
        "    for batch_features in test_loader:\r\n",
        "        batch_features = batch_features[0]\r\n",
        "        test_examples = batch_features.view(-1, 784)\r\n",
        "        reconstruction = model(test_examples)\r\n",
        "        break\r\n",
        "\r\n",
        "with torch.no_grad():\r\n",
        "    number = 10\r\n",
        "    plt.figure(figsize=(20, 4))\r\n",
        "    for index in range(number):\r\n",
        "        # display original\r\n",
        "        ax = plt.subplot(2, number, index + 1)\r\n",
        "        plt.imshow(test_examples[index].numpy().reshape(28, 28))\r\n",
        "        plt.gray()\r\n",
        "        ax.get_xaxis().set_visible(False)\r\n",
        "        ax.get_yaxis().set_visible(False)\r\n",
        "\r\n",
        "        # display reconstruction\r\n",
        "        ax = plt.subplot(2, number, index + 1 + number)\r\n",
        "        plt.imshow(reconstruction[index].numpy().reshape(28, 28))\r\n",
        "        plt.gray()\r\n",
        "        ax.get_xaxis().set_visible(False)\r\n",
        "        ax.get_yaxis().set_visible(False)\r\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPNQCEjlIWof"
      },
      "source": [
        "# **CITATIONS:**\r\n",
        "* https://debuggercafe.com/implementing-deep-autoencoder-in-pytorch/\r\n",
        "* https://towardsdatascience.com/implementing-an-autoencoder-in-tensorflow-2-0-5e86126e9f7\r\n",
        "* https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uyot7j0OJX4x"
      },
      "source": [
        "# Not working correctly ATM\r\n",
        "\r\n",
        "correct = 0\r\n",
        "total = 0\r\n",
        "\r\n",
        "with torch.no_grad():\r\n",
        "  for data in test_dataset:\r\n",
        "    X,Y = data\r\n",
        "    output = model(X.view(-1, 28*28))\r\n",
        "    for i in enumerate(output):  # idx is specific picture in batch; i is output array of size 10\r\n",
        "      if torch.argmax(i) == Y[i]:\r\n",
        "        correct += 1\r\n",
        "      total += 1\r\n",
        "\r\n",
        "print(\"Accuracy: \", round(correct/total, 3))\r\n",
        "\r\n",
        "print(torch.argmax(net(X[0].view(-1, 28*28))[0]))\r\n",
        "plt.imshow(X[0].view(28,28))\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}